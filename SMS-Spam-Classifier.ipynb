{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T12:26:54.077923Z",
     "start_time": "2020-06-25T12:26:54.067391Z"
    }
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T12:27:06.519801Z",
     "start_time": "2020-06-25T12:26:54.084251Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import the PySpark module\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create SparkSession object\n",
    "spark = SparkSession.builder \\\n",
    "                    .master('local[*]') \\\n",
    "                    .appName('sms') \\\n",
    "                    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T12:27:10.966241Z",
     "start_time": "2020-06-25T12:27:06.523747Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "\n",
    "# Specify column names and types\n",
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType()),\n",
    "    StructField(\"text\", StringType()),\n",
    "    StructField(\"label\", IntegerType())\n",
    "])\n",
    "\n",
    "# Load data from a delimited file\n",
    "sms = spark.read.csv(\"sms.csv\", sep=';', header=False, schema=schema)\n",
    "\n",
    "# Print schema of DataFrame\n",
    "sms.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T12:27:16.026579Z",
     "start_time": "2020-06-25T12:27:10.972581Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-----+------+\n",
      "| id|                text|label|length|\n",
      "+---+--------------------+-----+------+\n",
      "|  1|Sorry, I'll call ...|    0|    33|\n",
      "|  2|Dont worry. I gue...|    0|    30|\n",
      "|  3|Call FREEPHONE 08...|    1|    33|\n",
      "|  4|Win a 1000 cash p...|    1|    43|\n",
      "|  5|Go until jurong p...|    0|   111|\n",
      "|  6|Ok lar... Joking ...|    0|    29|\n",
      "|  7|Free entry in 2 a...|    1|   155|\n",
      "|  8|U dun say so earl...|    0|    49|\n",
      "|  9|Nah I don't think...|    0|    61|\n",
      "| 10|FreeMsg Hey there...|    1|   146|\n",
      "| 11|Even my brother i...|    0|    77|\n",
      "| 12|As per your reque...|    0|   158|\n",
      "| 13|WINNER!! As a val...|    1|   156|\n",
      "| 14|Had your mobile 1...|    1|   154|\n",
      "| 15|I'm gonna be home...|    0|   109|\n",
      "| 16|SIX chances to wi...|    1|   136|\n",
      "| 17|URGENT! You have ...|    1|   154|\n",
      "| 18|I've been searchi...|    0|   196|\n",
      "| 19|I HAVE A DATE ON ...|    0|    35|\n",
      "| 20|XXXMobileMovieClu...|    1|   149|\n",
      "+---+--------------------+-----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import length\n",
    "sms = sms.withColumn('length', length(sms['text']))\n",
    "sms.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T12:27:18.348296Z",
     "start_time": "2020-06-25T12:27:16.032815Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "|label|       avg(length)|\n",
      "+-----+------------------+\n",
      "|    0| 70.70188522892066|\n",
      "|    1|138.14457831325302|\n",
      "+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sms.groupBy('label').avg('length').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T12:27:18.380863Z",
     "start_time": "2020-06-25T12:27:18.356396Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      " |-- length: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sms.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T12:27:19.031701Z",
     "start_time": "2020-06-25T12:27:18.390910Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import the necessary functions\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "\n",
    "# Remove punctuation (REGEX provided) and numbers\n",
    "wrangled = sms.withColumn('text', regexp_replace(sms.text, '[_():;,.!?\\\\-]', ' '))\n",
    "wrangled = wrangled.withColumn('text', regexp_replace(wrangled.text, '[0-9]', ' '))\n",
    "\n",
    "# Merge multiple spaces\n",
    "wrangled = wrangled.withColumn('text', regexp_replace(wrangled.text, ' +', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T12:27:19.877710Z",
     "start_time": "2020-06-25T12:27:19.039515Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    0| 4827|\n",
      "|    1|  747|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wrangled.groupBy(\"label\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T12:27:20.351029Z",
     "start_time": "2020-06-25T12:27:19.890330Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-----+------+\n",
      "| id|                text|label|length|\n",
      "+---+--------------------+-----+------+\n",
      "|  1|Sorry I'll call l...|    0|    33|\n",
      "|  2|Dont worry I gues...|    0|    30|\n",
      "|  3| Call FREEPHONE now |    1|    33|\n",
      "|  4|Win a cash prize ...|    1|    43|\n",
      "|  5|Go until jurong p...|    0|   111|\n",
      "|  6|Ok lar Joking wif...|    0|    29|\n",
      "|  7|Free entry in a w...|    1|   155|\n",
      "|  8|U dun say so earl...|    0|    49|\n",
      "|  9|Nah I don't think...|    0|    61|\n",
      "| 10|FreeMsg Hey there...|    1|   146|\n",
      "| 11|Even my brother i...|    0|    77|\n",
      "| 12|As per your reque...|    0|   158|\n",
      "| 13|WINNER As a value...|    1|   156|\n",
      "| 14|Had your mobile m...|    1|   154|\n",
      "| 15|I'm gonna be home...|    0|   109|\n",
      "| 16|SIX chances to wi...|    1|   136|\n",
      "| 17|URGENT You have w...|    1|   154|\n",
      "| 18|I've been searchi...|    0|   196|\n",
      "| 19|I HAVE A DATE ON ...|    0|    35|\n",
      "| 20|XXXMobileMovieClu...|    1|   149|\n",
      "+---+--------------------+-----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wrangled.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T12:27:21.139355Z",
     "start_time": "2020-06-25T12:27:20.358319Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Break text into tokens at non-word characters\n",
    "tokenizer = Tokenizer(inputCol='text', outputCol='words')\n",
    "\n",
    "# Remove stop words\n",
    "remover = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol='terms')\n",
    "\n",
    "# Apply the hashing trick and transform to TF-IDF\n",
    "hasher = HashingTF(inputCol=remover.getOutputCol(), outputCol=\"hash\")\n",
    "idf = IDF(inputCol=hasher.getOutputCol(), outputCol=\"features\")\n",
    "\n",
    "# Create a logistic regression object and add everything to a pipeline\n",
    "logistic = LogisticRegression()\n",
    "pipeline = Pipeline(stages=[tokenizer, remover, hasher, idf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T12:27:27.561636Z",
     "start_time": "2020-06-25T12:27:21.143506Z"
    }
   },
   "outputs": [],
   "source": [
    "pipeline_model = pipeline.fit(wrangled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T12:27:27.884609Z",
     "start_time": "2020-06-25T12:27:27.569928Z"
    }
   },
   "outputs": [],
   "source": [
    "sms_transformed = pipeline_model.transform(wrangled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T12:27:27.989835Z",
     "start_time": "2020-06-25T12:27:27.892477Z"
    }
   },
   "outputs": [],
   "source": [
    "sms_train, sms_test = sms_transformed.randomSplit([0.8, 0.2], seed=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Weights (Handling Imbalanced Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T12:27:35.379424Z",
     "start_time": "2020-06-25T12:27:27.997413Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of ones are 601\n",
      "Percentage of ones are 13.421170165252343\n"
     ]
    }
   ],
   "source": [
    "dataset_size=float(sms_train.select(\"label\").count())\n",
    "numPositives=sms_train.select(\"label\").where('label == 1').count()\n",
    "per_ones=(float(numPositives)/float(dataset_size))*100\n",
    "numNegatives=float(dataset_size-numPositives)\n",
    "print('The number of ones are {}'.format(numPositives))\n",
    "print('Percentage of ones are {}'.format(per_ones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T12:27:35.399535Z",
     "start_time": "2020-06-25T12:27:35.386615Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BalancingRatio = 0.8657882983474765\n"
     ]
    }
   ],
   "source": [
    "BalancingRatio= numNegatives/dataset_size\n",
    "print('BalancingRatio = {}'.format(BalancingRatio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T12:27:38.641952Z",
     "start_time": "2020-06-25T12:27:35.410169Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+--------------------+\n",
      "|      classWeights|label|            features|\n",
      "+------------------+-----+--------------------+\n",
      "|0.1342117016525235|    0|(262144,[78820,10...|\n",
      "|0.8657882983474765|    1|(262144,[46213,10...|\n",
      "|0.8657882983474765|    1|(262144,[51247,77...|\n",
      "|0.1342117016525235|    0|(262144,[38555,52...|\n",
      "|0.8657882983474765|    1|(262144,[29259,68...|\n",
      "+------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when\n",
    "sms_train=sms_train.withColumn(\"classWeights\", when(sms_train.label == 1,BalancingRatio).otherwise(1-BalancingRatio))\n",
    "sms_train.select(\"classWeights\",\"label\",\"features\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T12:27:49.799635Z",
     "start_time": "2020-06-25T12:27:38.651456Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\",weightCol=\"classWeights\",maxIter=10)\n",
    "lr_model = lr.fit(sms_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T12:27:54.422980Z",
     "start_time": "2020-06-25T12:27:49.810358Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under ROC for test set 0.9720259552992109\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "prediction = lr_model.transform(sms_test)\n",
    "print(\"The area under ROC for test set {}\".format(evaluator.evaluate(prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T12:27:57.288666Z",
     "start_time": "2020-06-25T12:27:54.429921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+------------------------------------------+\n",
      "|label|prediction|probability                               |\n",
      "+-----+----------+------------------------------------------+\n",
      "|0    |0.0       |[0.9952162043831404,0.004783795616859571] |\n",
      "|0    |0.0       |[0.9999853417220804,1.4658277919459315E-5]|\n",
      "|1    |1.0       |[1.2911360078789951E-5,0.9999870886399211]|\n",
      "|1    |0.0       |[0.9769451956618017,0.023054804338198266] |\n",
      "|0    |0.0       |[0.9596079884065271,0.04039201159347307]  |\n",
      "+-----+----------+------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction.select('label', 'prediction', 'probability').show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T12:27:59.793467Z",
     "start_time": "2020-06-25T12:27:57.293621Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    0|       0.0|  942|\n",
      "|    1|       1.0|  126|\n",
      "|    1|       0.0|   20|\n",
      "|    0|       1.0|    8|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a confusion matrix\n",
    "prediction.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T12:28:09.411607Z",
     "start_time": "2020-06-25T12:27:59.803950Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision = 0.94\n",
      "recall    = 0.86\n",
      "F1 Score  = 0.90\n"
     ]
    }
   ],
   "source": [
    "# Calculate the elements of the confusion matrix\n",
    "TN = prediction.filter('prediction = 0 AND label = prediction').count()\n",
    "TP = prediction.filter('prediction = 1 AND label = prediction').count()\n",
    "FN = prediction.filter('prediction = 0 AND label != prediction').count()\n",
    "FP = prediction.filter('prediction = 1 AND label != prediction').count()\n",
    "\n",
    "precision = TP/(TP+FP)\n",
    "recall = TP/(TP+FN)\n",
    "F1score = (2*precision*recall)/(precision+recall)\n",
    "print('precision = {:.2f}\\nrecall    = {:.2f}\\nF1 Score  = {:.2f}'.format(precision, recall,F1score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search and Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T12:28:09.440248Z",
     "start_time": "2020-06-25T12:28:09.417812Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "params = ParamGridBuilder().addGrid(hasher.numFeatures, [1024, 4096, 16384]) \\\n",
    "                           .addGrid(hasher.binary, [True, False]) \\\n",
    "                           .addGrid(lr.regParam, [0.01, 0.1, 1.0, 10.0]) \\\n",
    "                           .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
    "                           .build()\n",
    "\n",
    "cv = CrossValidator(estimator=lr, estimatorParamMaps=params,evaluator = evaluator, numFolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T12:51:28.340962Z",
     "start_time": "2020-06-25T12:28:09.446319Z"
    }
   },
   "outputs": [],
   "source": [
    "lr_cv_model = cv.fit(sms_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T12:51:29.129747Z",
     "start_time": "2020-06-25T12:51:28.345949Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9843186733958208"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(lr_cv_model.transform(sms_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T12:51:29.910658Z",
     "start_time": "2020-06-25T12:51:29.134733Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under ROC for test set after cv0.9843186733958208\n"
     ]
    }
   ],
   "source": [
    "prediction_cv = lr_cv_model.transform(sms_test)\n",
    "print(\"The area under ROC for test set after cv{}\".format(evaluator.evaluate(prediction_cv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T12:51:32.722137Z",
     "start_time": "2020-06-25T12:51:29.912652Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision = 0.98\n",
      "recall    = 0.88\n",
      "F1 Score  = 0.93\n"
     ]
    }
   ],
   "source": [
    "# Calculate the elements of the confusion matrix\n",
    "TN = prediction_cv.filter('prediction = 0 AND label = prediction').count()\n",
    "TP = prediction_cv.filter('prediction = 1 AND label = prediction').count()\n",
    "FN = prediction_cv.filter('prediction = 0 AND label != prediction').count()\n",
    "FP = prediction_cv.filter('prediction = 1 AND label != prediction').count()\n",
    "\n",
    "precision = TP/(TP+FP)\n",
    "recall = TP/(TP+FN)\n",
    "F1score = (2*precision*recall)/(precision+recall)\n",
    "print('precision = {:.2f}\\nrecall    = {:.2f}\\nF1 Score  = {:.2f}'.format(precision, recall,F1score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
